# FaceQCNet

**FaceQCNet** Ã¨ un framework modulare per l'analisi avanzata della qualitÃ  e degli attributi facciali soft in immagini statiche. Combina pipeline di deep learning basate su **MagFace**, **Facer** (FaRL) e **FairFace** per effettuare inferenze affidabili e demograficamente sensibili, utili per scenari di fairness audit, bias mitigation e soft-biometric profiling.

---

## Obiettivo
FaceQCNet Ã¨ uno strumento che ci aiuta a scegliere solo le immagini sintetiche nitide e realistiche, 
per essere usate in un progetto di intelligenza artificiale. 
Dopo aver selezionato le immagini migliori, analizza il volto di ciascuna per capire alcune caratteristiche, 
come il colore dei capelli, lâ€™etnia, il genere e lâ€™etÃ . In questo modo possiamo sapere esattamente che tipo di 
persone stiamo rappresentando con queste immagini artificiali. 
Tutto questo ci serve per allenare meglio un modello di intelligenza artificiale, chiamato Slim-CNN, cosÃ¬ che non 
sia ingiusto verso alcune categorie di persone (ad esempio donne o persone di pelle scura).

FaceQCNet Ã¨ un modulo di prefiltraggio e annotazione semantica volto alla selezione di immagini sintetiche ad alta qualitÃ , 
destinate alla mitigazione del bias nei modelli di riconoscimento di attributi facciali soft. 
Le immagini vengono selezionate solo se superano una soglia di qualitÃ  visiva (quality score â‰¥ 20), calcolata tramite il modello MagFace. 
Successivamente, ciascuna immagine viene analizzata mediante due pipeline:
- **Facer** per lâ€™estrazione di attributi binari secondo lo schema CelebA (es. colore dei capelli, presenza di occhiali, sorriso);
- **FairFace** per la stima di attributi demografici sensibili: etnia, genere ed etÃ .

Questa doppia annotazione consente di costruire un dataset sintetico demograficamente controllato. 
Il dataset risultante sarÃ  impiegato per il riaddestramento della rete Slim-CNN, con lâ€™obiettivo di migliorare lâ€™equitÃ  delle predizioni, 
soprattutto nei confronti di gruppi demografici sottorappresentati nei dataset reali.

---


## ðŸ§¬ Architettura del Sistema

FaceQCNet Ã¨ composto da tre pipeline interconnesse:

### 1. **MagFace Quality Scoring**
- Architettura: `iresnet100`
- Metodo: magnitudo del deep feature embedding (L2-norm)
- Soglia di accettazione predefinita: `||f||â‚‚ â‰¥ 20.0`
- Uscita: immagini filtrate ad alta qualitÃ 
- Fonte: [MagFace â€“ IrvingMeng/MagFace](https://github.com/IrvingMeng/MagFace)

### 2. **Facer Attribute Recognition**
- Backbone: `retinaface/mobilenet` (face detection)
- Classificatore: `farl/celeba/224` (multi-label attribute prediction)
- Dataset di riferimento: CelebA
- Uscita: probabilitÃ  binarie per 40+ attributi soft
- Fonte: [FacePerceiver/facer](https://github.com/FacePerceiver/facer)

### 3. **FairFace Demographic Classification**
- Modello: `resnet34` fine-tuned per task multi-classe
- Output: classificazione [etnia (7), genere (2), etÃ  (9 classi)]
- Dataset: FairFace, bilanciato per razza/genere
- Fonte: [dchen236/FairFace](https://github.com/dchen236/FairFace)

---

## ðŸ›  Requisiti e Setup

### Dipendenze principali

- `torch`, `torchvision`, `facer`
- `Pillow`, `tqdm`, `gdown`

### Installazione

```bash
git clone https://github.com/tuo-username/faceqcnet.git
cd faceqcnet
pip install -r requirements.txt
```

### Scaricamento modelli

- `magface_epoch_00025.pth` sarÃ  scaricato automaticamente via `gdown`
- `res34_fair_align_multi_7_20190809.pt` va posto in `models/`

---

## ðŸ“ˆ Pipeline di Inferenza

### 1. Filtraggio qualitÃ  volto con MagFace

```bash
python script/quality_check.py
```

**Input:** `data/synthetic/`  
**Output:** `data/quality_images/` + `quality_scores.txt`

- Pre-processing: resize(112Ã—112), normalize [-1, 1]
- Threshold decision based on L2-norm of embedding

### 2. Estrazione attributi (Facer + FairFace)

```bash
python script/extract_attributes.py
```

**Input:** `data/quality_images/`  
**Output:** `.txt` descrittivi in `data/attributes_detected/`

- Facer â†’ parsing colore capelli, sorriso, trucco, barba, occhiali...
- FairFace â†’ classificazione demografica robusta (etÃ , genere, etnia)

---

## ðŸ“‚ Organizzazione del Repository

```
faceqcnet/
â”‚
â”œâ”€â”€ models/                     # Contiene pesi pre-addestrati
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ synthetic/              # Immagini non valutate
â”‚   â”œâ”€â”€ quality_images/        # Output filtrato da MagFace
â”‚   â””â”€â”€ attributes_detected/   # File testuali con predizioni
â”œâ”€â”€ script/                       # Codice sorgente
â”‚   â”œâ”€â”€ quality_check.py
â”‚   â””â”€â”€ extract_attributes.py
â”‚   â””â”€â”€ clean_outputs.py       # Pulisce le directory data/quality_images e attributes_detected
â”œâ”€â”€ README.md
â””â”€â”€ NOTICE
```

---

## ðŸ“¤ Output Esemplificativo

```
COLORE CAPELLI:
- Black Hair (0.96)
- Blond Hair (0.54)

Attributi rilevati:
Smiling: 0.91
Wearing_Lipstick: 0.88
Heavy_Makeup: 0.65
Eyeglasses: 0.12

--- FairFace Prediction ---
Razza stimata: Southeast_Asian
Genere stimato: Female
EtÃ  stimata: 30-39
```

---

## ðŸ“œ Licenza

**FaceQCNet** Ã¨ distribuito sotto licenza **Apache License 2.0**.

Componenti terze incluse:

- **MagFace** â€“ Apache 2.0
- **Facer** â€“ MIT License
- **FairFace** â€“ Creative Commons Attribution 4.0 (CC BY 4.0)

Consulta il file [`NOTICE`](NOTICE) per dettagli completi sulle attribuzioni.

---

## ðŸ“š Citazioni Originali

Se utilizzi questo framework in pubblicazioni accademiche, cita i seguenti lavori:

- MagFace: *CVPR 2021 â€“ Meng et al.*
- Facer: *FaceXFormer/FaRL â€“ 2023-2024*
- FairFace: *CVPR 2020 â€“ K. Joumaa & D. Chen*

---

## ðŸ“© Contatti

Jacopo de Dominicis  
MITIGAZIONE BIAS DEMOGRAFICO â€“ Fondamenti di Visione e Biometria 2025  
Email: jacopodedominicisdeveloper@gmail.com

